"""
ë¯¼ê°ì„± ê²€ì¦ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸

ì´ ëª¨ë“ˆì€ analyze_sensitivity_with_agent í•¨ìˆ˜ì˜ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pytest
import logging
from dotenv import load_dotenv
from unittest.mock import patch, MagicMock
from datetime import datetime
import uuid

from src.agents.sensitivity_validator import (
    analyze_sensitivity_with_agent,
    SensitivityValidationRequest,
    SensitivityAnalysisResult
)
from src.models.job_posting import (
    UserInput, 
    JobTypeEnum, 
    ExperienceLevel,
    SalaryInfo,
    SalaryType,
    WorkLocation,
    WorkLocationEnum
)
from src.exceptions import ValidationError

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv(override=True)


class TestSensitivityValidator:
    """ë¯¼ê°ì„± ê²€ì¦ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    @pytest.fixture
    def safe_user_input(self):
        """ë¯¼ê°í•œ ë‚´ìš©ì´ ì—†ëŠ” ì•ˆì „í•œ ì‚¬ìš©ì ì…ë ¥"""
        return UserInput(
            job_title="ë°±ì—”ë“œ ê°œë°œì",
            company_name="í…Œí¬ ìŠ¤íƒ€íŠ¸ì—…",
            requirements=[
                "Python 3ë…„ ì´ìƒ ê²½í—˜",
                "Django ë˜ëŠ” FastAPI í”„ë ˆì„ì›Œí¬ ê²½í—˜",
                "RESTful API ì„¤ê³„ ë° ê°œë°œ ê²½í—˜",
                "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° ìµœì í™” ê²½í—˜"
            ],
            preferred_qualifications=[
                "AWS í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ê²½í—˜",
                "Docker, Kubernetes ê²½í—˜",
                "CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜"
            ],
            job_type=JobTypeEnum.FULL_TIME,
            experience_level=ExperienceLevel.MID,
            salary_info=SalaryInfo(
                type=SalaryType.ANNUAL,
                min_amount=4000,
                max_amount=6000,
                currency="KRW",
                is_negotiable=True
            ),
            work_location=WorkLocation(
                type=WorkLocationEnum.HYBRID,
                city="ì„œìš¸",
                country="í•œêµ­"
            ),
            additional_info=["ìœ ì—°ê·¼ë¬´ì œ", "ê°œë°œì ì„±ì¥ ì§€ì›"]
        )
    
    @pytest.fixture
    def sensitive_user_input(self):
        """ë¯¼ê°í•œ ë‚´ìš©ì´ í¬í•¨ëœ ì‚¬ìš©ì ì…ë ¥"""
        return UserInput(
            job_title="í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
            company_name="ì „í†µ ê¸°ì—…",
            requirements=[
                "React 2ë…„ ì´ìƒ ê²½í—˜",
                "25ì„¸ ì´ìƒ 35ì„¸ ë¯¸ë§Œë§Œ ì§€ì› ê°€ëŠ¥",  # ë‚˜ì´ ì°¨ë³„
                "ë‚¨ì„± ê°œë°œì ìš°ëŒ€",  # ì„±ë³„ ì°¨ë³„
                "ì„œìš¸ ê±°ì£¼ìë§Œ ì§€ì› ê°€ëŠ¥"  # ì§€ì—­ ì°¨ë³„
            ],
            preferred_qualifications=[
                "ë¯¸í˜¼ì ìš°ëŒ€",  # ê²°í˜¼ ì—¬ë¶€ ì°¨ë³„
                "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ì œì¶œ í•„ìˆ˜",  # ê°œì¸ì •ë³´ ìš”êµ¬
                "ê°€ì¡±ì‚¬í•­ ìƒì„¸ ê¸°ì¬"  # ì‚¬ìƒí™œ ì¹¨í•´
            ],
            job_type=JobTypeEnum.FULL_TIME,
            experience_level=ExperienceLevel.JUNIOR,
            additional_info=["ì™¸ëª¨ ë‹¨ì •í•œ ë¶„", "ì¢…êµ í™œë™ ì°¸ì—¬ í•„ìˆ˜"]  # ì™¸ëª¨/ì¢…êµ ì°¨ë³„
        )
    
    @pytest.fixture
    def mock_successful_agent_response(self):
        """ì„±ê³µì ì¸ ì—ì´ì „íŠ¸ ì‘ë‹µ ëª¨ì˜ ê°ì²´"""
        mock_response = {
            "structured_response": SensitivityAnalysisResult(
                is_sensitive=False,
                risk_score=2.0,
                detected_issues=[],
                requires_human_review=False,
                sanitized_version=None
            )
        }
        return mock_response
    
    @pytest.fixture 
    def mock_sensitive_agent_response(self):
        """ë¯¼ê°í•œ ë‚´ìš©ì´ ê°ì§€ëœ ì—ì´ì „íŠ¸ ì‘ë‹µ ëª¨ì˜ ê°ì²´"""
        mock_response = {
            "structured_response": SensitivityAnalysisResult(
                is_sensitive=True,
                risk_score=8.5,
                detected_issues=[
                    "ë‚˜ì´ ì œí•œ (25ì„¸ ì´ìƒ 35ì„¸ ë¯¸ë§Œë§Œ ì§€ì› ê°€ëŠ¥)",
                    "ì„±ë³„ ì°¨ë³„ (ë‚¨ì„± ê°œë°œì ìš°ëŒ€)", 
                    "ì§€ì—­ ì°¨ë³„ (ì„œìš¸ ê±°ì£¼ìë§Œ ì§€ì› ê°€ëŠ¥)",
                    "ê²°í˜¼ ì—¬ë¶€ ì°¨ë³„ (ë¯¸í˜¼ì ìš°ëŒ€)",
                    "ê°œì¸ì •ë³´ ê³¼ë„ ìš”êµ¬ (ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ì œì¶œ í•„ìˆ˜)",
                    "ì‚¬ìƒí™œ ì¹¨í•´ (ê°€ì¡±ì‚¬í•­ ìƒì„¸ ê¸°ì¬)"
                ],
                requires_human_review=True,
                sanitized_version="ìˆ˜ì •ì´ í•„ìš”í•œ ì—¬ëŸ¬ ë¯¼ê°í•œ í‘œí˜„ë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        }
        return mock_response
    
    def test_analyze_sensitivity_safe_content_real(self, safe_user_input):
        """
        ì‹¤ì œ LLMì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸
        
        ì£¼ì˜: ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ API í‚¤ê°€ í•„ìš”í•˜ê³  ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        # ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ì„ íƒì  ì‹¤í–‰)
        pytest.skip("ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”")
        
        request = SensitivityValidationRequest(user_input=safe_user_input)
        
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        # ê²°ê³¼ ê²€ì¦
        assert isinstance(result, SensitivityAnalysisResult)
        assert isinstance(metadata, dict)
        
        # ì•ˆì „í•œ ì½˜í…ì¸ ì´ë¯€ë¡œ ë¯¼ê°ì„±ì´ ë‚®ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
        assert result.is_sensitive in [True, False]  # ëª¨ë¸ íŒë‹¨ì— ë”°ë¼ ê²°ì •
        assert 0 <= result.risk_score <= 10
        assert isinstance(result.detected_issues, list)
        assert isinstance(result.requires_human_review, bool)
        
        # ë©”íƒ€ë°ì´í„° ê²€ì¦
        assert "thread_id" in metadata
        assert "generated_by" in metadata
        assert metadata["generated_by"] == "gpt-4o-mini"
        
        logger.info(f"ì•ˆì „í•œ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼: ë¯¼ê°ì„±={result.is_sensitive}, ìœ„í—˜ë„={result.risk_score}")
    
    def test_analyze_sensitivity_sensitive_content_real(self, sensitive_user_input):
        """
        ì‹¤ì œ LLMì„ ì‚¬ìš©í•œ ë¯¼ê°í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸
        
        ì£¼ì˜: ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ API í‚¤ê°€ í•„ìš”í•˜ê³  ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        # ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ì„ íƒì  ì‹¤í–‰)
        pytest.skip("ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”")
        
        request = SensitivityValidationRequest(user_input=sensitive_user_input)
        
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        # ê²°ê³¼ ê²€ì¦
        assert isinstance(result, SensitivityAnalysisResult)
        assert isinstance(metadata, dict)
        
        # ë¯¼ê°í•œ ì½˜í…ì¸ ì´ë¯€ë¡œ ë†’ì€ ìœ„í—˜ë„ ì˜ˆìƒ
        assert result.is_sensitive == True  # ëª…í™•íˆ ë¯¼ê°í•œ ë‚´ìš©ì´ í¬í•¨ë¨
        assert result.risk_score >= 5.0  # ë†’ì€ ìœ„í—˜ë„ ì˜ˆìƒ
        assert len(result.detected_issues) > 0  # ë¬¸ì œê°€ ê°ì§€ë˜ì–´ì•¼ í•¨
        assert result.requires_human_review == True  # ì‚¬ëŒì˜ ê²€í†  í•„ìš”
        
        # ë©”íƒ€ë°ì´í„° ê²€ì¦
        assert "thread_id" in metadata
        assert "generated_by" in metadata
        
        logger.info(f"ë¯¼ê°í•œ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼: ë¯¼ê°ì„±={result.is_sensitive}, ìœ„í—˜ë„={result.risk_score}")
        logger.info(f"ê°ì§€ëœ ë¬¸ì œ ìˆ˜: {len(result.detected_issues)}")
    
    @patch('src.agents.sensitivity_validator.create_react_agent')
    @patch('src.agents.sensitivity_validator.init_chat_model')
    def test_analyze_sensitivity_safe_content_mock(
        self, 
        mock_init_chat_model, 
        mock_create_react_agent,
        safe_user_input,
        mock_successful_agent_response
    ):
        """Mockì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_llm = MagicMock()
        mock_init_chat_model.return_value = mock_llm
        
        mock_agent = MagicMock()
        mock_agent.invoke.return_value = mock_successful_agent_response
        mock_create_react_agent.return_value = mock_agent
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        request = SensitivityValidationRequest(user_input=safe_user_input)
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        # Mock í˜¸ì¶œ í™•ì¸
        mock_init_chat_model.assert_called_once()
        mock_create_react_agent.assert_called_once()
        mock_agent.invoke.assert_called_once()
        
        # ê²°ê³¼ ê²€ì¦
        assert isinstance(result, SensitivityAnalysisResult)
        assert result.is_sensitive == False
        assert result.risk_score == 2.0
        assert len(result.detected_issues) == 0
        assert result.requires_human_review == False
        
        # ë©”íƒ€ë°ì´í„° ê²€ì¦
        assert isinstance(metadata, dict)
        assert "thread_id" in metadata
        assert "generated_by" in metadata
        
        logger.info("Mockì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    @patch('src.agents.sensitivity_validator.create_react_agent')
    @patch('src.agents.sensitivity_validator.init_chat_model')
    def test_analyze_sensitivity_sensitive_content_mock(
        self, 
        mock_init_chat_model, 
        mock_create_react_agent,
        sensitive_user_input,
        mock_sensitive_agent_response
    ):
        """Mockì„ ì‚¬ìš©í•œ ë¯¼ê°í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_llm = MagicMock()
        mock_init_chat_model.return_value = mock_llm
        
        mock_agent = MagicMock()
        mock_agent.invoke.return_value = mock_sensitive_agent_response
        mock_create_react_agent.return_value = mock_agent
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        request = SensitivityValidationRequest(user_input=sensitive_user_input)
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        # Mock í˜¸ì¶œ í™•ì¸
        mock_init_chat_model.assert_called_once()
        mock_create_react_agent.assert_called_once()
        mock_agent.invoke.assert_called_once()
        
        # ê²°ê³¼ ê²€ì¦
        assert isinstance(result, SensitivityAnalysisResult)
        assert result.is_sensitive == True
        assert result.risk_score == 8.5
        assert len(result.detected_issues) > 0
        assert result.requires_human_review == True
        
        # ê°ì§€ëœ ë¬¸ì œ ìƒì„¸ í™•ì¸ (List[str] í˜•íƒœë¡œ ë³€ê²½ë¨)
        assert any("ë‚˜ì´ ì œí•œ" in issue for issue in result.detected_issues)
        assert any("ì„±ë³„ ì°¨ë³„" in issue for issue in result.detected_issues)
        assert any("ê°œì¸ì •ë³´" in issue for issue in result.detected_issues)
        
        # ë©”íƒ€ë°ì´í„° ê²€ì¦
        assert isinstance(metadata, dict)
        assert "thread_id" in metadata
        assert "generated_by" in metadata
        
        logger.info("Mockì„ ì‚¬ìš©í•œ ë¯¼ê°í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸ í†µê³¼")
        logger.info(f"ê°ì§€ëœ ë¬¸ì œ ë‚´ìš©: {result.detected_issues}")
    
    @patch('src.agents.sensitivity_validator.create_react_agent')
    @patch('src.agents.sensitivity_validator.init_chat_model')
    def test_analyze_sensitivity_error_handling(
        self, 
        mock_init_chat_model, 
        mock_create_react_agent,
        safe_user_input
    ):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # Mockì´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ë„ë¡ ì„¤ì •
        mock_init_chat_model.side_effect = Exception("API ì—°ê²° ì‹¤íŒ¨")
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì˜ˆì™¸ í™•ì¸
        request = SensitivityValidationRequest(user_input=safe_user_input)
        
        with pytest.raises(ValidationError) as exc_info:
            analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        assert "ë¯¼ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ" in str(exc_info.value)
        logger.info("ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    @patch('src.agents.sensitivity_validator.create_react_agent')
    @patch('src.agents.sensitivity_validator.init_chat_model')
    def test_analyze_sensitivity_no_response(
        self, 
        mock_init_chat_model, 
        mock_create_react_agent,
        safe_user_input
    ):
        """ì‘ë‹µ ì—†ìŒ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì • - ì‘ë‹µì—ì„œ generate_structured_responseê°€ ì—†ëŠ” ê²½ìš°
        mock_llm = MagicMock()
        mock_init_chat_model.return_value = mock_llm
        
        mock_agent = MagicMock()
        mock_agent.invoke.return_value = {"other_key": "value"}  # ì˜ëª»ëœ ì‘ë‹µ
        mock_create_react_agent.return_value = mock_agent
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì˜ˆì™¸ í™•ì¸
        request = SensitivityValidationRequest(user_input=safe_user_input)
        
        with pytest.raises(ValidationError) as exc_info:
            analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        
        assert "ë¯¼ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" in str(exc_info.value)
        logger.info("ì‘ë‹µ ì—†ìŒ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")


# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ë“¤
def run_real_test_safe():
    """ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    safe_input = UserInput(
        job_title="í’€ìŠ¤íƒ ê°œë°œì",
        company_name="í˜ì‹  ê¸°ì—…",
        requirements=[
            "JavaScript ë° Python ê²½í—˜",
            "í”„ë¡ íŠ¸ì—”ë“œ ë° ë°±ì—”ë“œ ê°œë°œ ê²½í—˜",
            "í˜‘ì—… ëŠ¥ë ¥ ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥"
        ],
        preferred_qualifications=[
            "í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ê²½í—˜",
            "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ê²½í—˜"
        ],
        job_type=JobTypeEnum.FULL_TIME,
        experience_level=ExperienceLevel.MID,
        additional_info=["ìœ ì—°ê·¼ë¬´ì œ", "ì„±ì¥ ì§€ì› í”„ë¡œê·¸ë¨"]
    )
    
    request = SensitivityValidationRequest(user_input=safe_input)
    
    try:
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        print(f"âœ… ì•ˆì „í•œ ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ:")
        print(f"   ë¯¼ê°ì„±: {result.is_sensitive}")
        print(f"   ìœ„í—˜ë„: {result.risk_score}")
        print(f"   ê°ì§€ëœ ë¬¸ì œ ìˆ˜: {len(result.detected_issues)}")
        print(f"   ì‚¬ëŒ ê²€í†  í•„ìš”: {result.requires_human_review}")
        print(f"   ëª¨ë¸: {metadata['generated_by']}")
        return result, metadata
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None, None


def run_real_test_sensitive():
    """ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•œ ë¯¼ê°í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    sensitive_input = UserInput(
        job_title="ë§ˆì¼€íŒ… ë‹´ë‹¹ì",
        company_name="ì „í†µ íšŒì‚¬",
        requirements=[
            "30ì„¸ ë¯¸ë§Œ ì—¬ì„±ë§Œ ì§€ì› ê°€ëŠ¥",  # ë‚˜ì´ + ì„±ë³„ ì°¨ë³„
            "ìš©ëª¨ ë‹¨ì •í•˜ê³  í‚¤ 160cm ì´ìƒ",  # ì™¸ëª¨ ì°¨ë³„
            "ë¯¸í˜¼ì ìš°ëŒ€, ê²°í˜¼ ê³„íš ì—†ëŠ” ë¶„"  # ê²°í˜¼ ìƒíƒœ ì°¨ë³„
        ],
        preferred_qualifications=[
            "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ ì œì¶œ",  # ê°œì¸ì •ë³´ ê³¼ë„ ìš”êµ¬
            "íŠ¹ì • ì¢…êµ ì‹ ì ìš°ëŒ€"  # ì¢…êµ ì°¨ë³„
        ],
        job_type=JobTypeEnum.FULL_TIME,
        experience_level=ExperienceLevel.ENTRY,
        additional_info=["ì™¸ëª¨ ì¤‘ì‹œ", "íŠ¹ì • ì¢…êµ ìš°ëŒ€"]
    )
    
    request = SensitivityValidationRequest(user_input=sensitive_input)
    
    try:
        result, metadata = analyze_sensitivity_with_agent(request, thread_id=str(uuid.uuid4()))
        print(f"âœ… ë¯¼ê°í•œ ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ:")
        print(f"   ë¯¼ê°ì„±: {result.is_sensitive}")
        print(f"   ìœ„í—˜ë„: {result.risk_score}")
        print(f"   ê°ì§€ëœ ë¬¸ì œ ìˆ˜: {len(result.detected_issues)}")
        print(f"   ì‚¬ëŒ ê²€í†  í•„ìš”: {result.requires_human_review}")
        print(f"   ëª¨ë¸: {metadata['generated_by']}")
        
        if result.detected_issues:
            print("   ê°ì§€ëœ ë¬¸ì œ ìƒì„¸:")
            for issue in result.detected_issues:
                print(f"    - {issue}")
        
        return result, metadata
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None, None


if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ì‹œ ì‹¤ì œ API í…ŒìŠ¤íŠ¸ ìˆ˜í–‰"""
    print("ğŸ§ª ë¯¼ê°ì„± ê²€ì¦ ì—ì´ì „íŠ¸ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n")
    
    print("1. ì•ˆì „í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸:")
    run_real_test_safe()
    print()
    
    print("2. ë¯¼ê°í•œ ì½˜í…ì¸  í…ŒìŠ¤íŠ¸:")
    run_real_test_sensitive()
    print()
    
    print("ğŸ’¡ ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰: pytest tests/test_sensitivity_validator.py -v")
